{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe4c8034",
   "metadata": {},
   "source": [
    "# Implementing CCSD with Pair Natural Orbitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9991fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tutorial implementing PNO-CCSD, simplified version of DLPNO-CCSD method\"\"\"\n",
    "\n",
    "__authors__ = \"A. Jiang and A. Wallace\"\n",
    "__credits__ = \"A. Jiang and J. Madriaga\"\n",
    "__email__   = \"ajiang10224@gmail.com\"\n",
    "\n",
    "__copyright__ = \"(c) 2014-2023, The Psi4NumPy Developers\"\n",
    "__license__   = \"BSD-3-Clause\"\n",
    "__date__      = \"05/15/2023\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1a2b4d6",
   "metadata": {},
   "source": [
    "## I. Theoretical Overview\n",
    "In this tutorial, we are implementing PNO-CCSD, or Coupled-cluster theory with pair natural orbitals. Pair naturals reduce the size of the virtual space of each pair of occupied molecular orbitals by diagonalizing the pair density.\n",
    "    \n",
    "$$ \\mathbf{D}_{ij} = \\mathbf{\\widetilde{t}}_{ij}\\mathbf{t}_{ij}^{T} + \\mathbf{\\widetilde{t}}_{ij}^{T}\\mathbf{t}_{ij}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mathbf{\\widetilde{t}}_{ij} = 2\\mathbf{t}_{ij} - \\mathbf{t}_{ij}^{T} $$\n",
    "\n",
    "The pair density is then diagonalized to form the PNO transformation matrix $\\mathbf{X}^{PNO,ij}$, and the eigenvalues form the occupation numbers $\\mathbf{n}^{occ,ij}$.\n",
    "\n",
    "$$ \\mathbf{D}_{ij}\\mathbf{X}^{PNO,ij} = \\mathbf{X}^{PNO,ij}\\mathbf{n}^{occ,ij} $$\n",
    "\n",
    "The columns of the $\\mathbf{X}$ matrix are then truncated if the occupation number falls below a certain tolerance. In larger molecules, the size of the PNO space of each pair of occupied molecular orbitals is constant.\n",
    "\n",
    "The transformation from canonical MOs to PNOs of a pair $ij$ is given by this formula:\n",
    "\n",
    "$$ |\\Phi_{a_{ij}}> = X^{PNO,ij}_{aa_{ij}}|\\Phi_{a}> $$\n",
    "\n",
    "Applying PNOs to CCSD theory reduces its scaling from $\\mathcal{O}(N^{6})$ to $\\mathcal{O}(N^{4})$, though the MP2 step still takes $\\mathcal{O}(N^{5})$. In the state of the art DLPNO (Domain-Localized Pair Natural Orbital) approaches to Coupled-Cluster methods, the PNOs are not expanded in terms of canonical virtual orbitals, but in terms of Projected Atomic Orbitals (PAOs). Also, the occupied molecular orbital space is localized through means such as Foster-Boys or Pipek-Mezey localization, and local density-fitting is applied to localize the set of auxiliary basis functions for each local MO pair $ij$. The combination of these techniques allow DLPNO-CCSD to approach linear-scaling with larger molecules. In this tutotial, for simplicity and pedagogical purposes, we will not make use of these techniques."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca5b75e0",
   "metadata": {},
   "source": [
    "## II. Implementation\n",
    "We will now write a program that runs the PNO-CCSD algorithm. First, we need to import Psi4 and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1089f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Memory set to   1.863 GiB by Python driver.\n"
     ]
    }
   ],
   "source": [
    "import psi4\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "psi4.set_memory(int(2e9))\n",
    "numpy_memory = 2\n",
    "psi4.core.set_output_file('output.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c3c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set molecule and wavefunction, and run preceeding SCF computation\n",
    "mol = psi4.geometry(\"\"\"\n",
    "0 1\n",
    "O\n",
    "H 1 0.96\n",
    "H 1 0.96 2 104.5\n",
    "symmetry c1\n",
    "\"\"\")\n",
    "\n",
    "psi4.set_options({\n",
    "    'basis': 'cc-pVDZ',\n",
    "    'scf_type': 'df',\n",
    "    'mp2_type': 'df',\n",
    "    'cc_type': 'df',\n",
    "    'nat_orbs': False,\n",
    "    'e_convergence': 1.0e-8,\n",
    "    'd_convergence': 1.0e-8,\n",
    "    'r_convergence': 1.0e-6\n",
    "})\n",
    "\n",
    "# Get the SCF energy and wavefunction\n",
    "scf_e, scf_wfn = psi4.energy('scf', return_wfn=True)\n",
    "\n",
    "# Number of occupied orbitals and MOs\n",
    "ndocc = scf_wfn.nalpha()\n",
    "nmo = scf_wfn.nmo()\n",
    "nvirt = nmo - ndocc\n",
    "\n",
    "# Get orbital energies, cast into NumPy array, and separate occupied & virtual\n",
    "eps = np.asarray(scf_wfn.epsilon_a())\n",
    "e_ij = eps[:ndocc]\n",
    "e_ab = eps[ndocc:]\n",
    "\n",
    "# Get MO coefficients\n",
    "Cmo = np.asarray(scf_wfn.Ca())\n",
    "Cocc = Cmo[:,:ndocc]\n",
    "Cvirt = Cmo[:,ndocc:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "437d0451",
   "metadata": {},
   "source": [
    "Next, we need to form the density-fitted ERIs in the MO basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e26810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==> Density Fitted ERIs <==\n",
    "# Build auxiliary basis set\n",
    "aux = psi4.core.BasisSet.build(mol, \"DF_BASIS_SCF\", \"\", \"RIFIT\", \"cc-pVDZ\")\n",
    "\n",
    "# Build instance of Mints object\n",
    "orb = scf_wfn.basisset()\n",
    "mints = psi4.core.MintsHelper(orb)\n",
    "\n",
    "# Build a zero basis\n",
    "zero_bas = psi4.core.BasisSet.zero_ao_basis_set()\n",
    "\n",
    "# Raw 3-index\n",
    "Ppq = np.squeeze(mints.ao_eri(aux, zero_bas, orb, orb))\n",
    "\n",
    "# Build and invert the Coulomb metric\n",
    "metric = mints.ao_eri(aux, zero_bas, aux, zero_bas)\n",
    "metric.power(-0.5, 1.e-14)\n",
    "metric = np.squeeze(metric)\n",
    "\n",
    "Qpq = np.einsum(\"QP,Ppq->Qpq\", metric, Ppq, optimize=True)\n",
    "\n",
    "# Transform into MO basis\n",
    "Qia = np.einsum('pi,Qpq,qa->Qia', Cocc, Qpq, Cvirt, optimize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ee7babf",
   "metadata": {},
   "source": [
    "Next up, we compute the amplitudes from MP2, in order to form our PNOs (pair natural orbitals), we need to compute the amplitudes with each MO pair. We later use this information to compute the pair density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11fe511",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_ijab = np.empty((ndocc, ndocc, nvirt, nvirt), dtype=np.float64) # (ia|jb) integrals\n",
    "T_ijab = np.empty((ndocc, ndocc, nvirt, nvirt), dtype=np.float64) # amplitudes\n",
    "Tt_ijab = np.empty((ndocc, ndocc, nvirt, nvirt), dtype=np.float64) # anti-symmetrized amplitudes\n",
    "\n",
    "e_vv = e_ab.reshape(-1, 1) + e_ab\n",
    "\n",
    "E_MP2 = 0.0\n",
    "for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "    K_ijab[i,j] = np.einsum('Qa,Qb->ab', Qia[:,i,:], Qia[:,j,:], optimize=True)\n",
    "    T_ijab[i,j] = K_ijab[i,j] / (e_ij[i] + e_ij[j] - e_vv)\n",
    "    Tt_ijab[i,j] = 2.0 * T_ijab[i,j] - T_ijab[i, j].transpose()\n",
    "    E_MP2 += np.dot(Tt_ijab[i,j].flatten(), K_ijab[i,j].flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a414b2d5",
   "metadata": {},
   "source": [
    "Next, we perform a sanity check, to ensure that our DF-MP2 energy matches the Psi4 DF-MP2 energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3579bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our MP2 Correlation Energy: -0.2041247114211424\n",
      "PSI MP2 Correlation Energy: -0.2041247114217839\n"
     ]
    }
   ],
   "source": [
    "E_MP2_PSI = psi4.energy('mp2')\n",
    "\n",
    "print('Our MP2 Correlation Energy:', E_MP2)\n",
    "print('PSI MP2 Correlation Energy:', E_MP2_PSI - scf_e)\n",
    "assert(np.allclose(scf_e + E_MP2, E_MP2_PSI))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afa2c48a",
   "metadata": {},
   "source": [
    "Next, we compute and diagonalize our pair densities to get the transformation matrix from canonical MOs to PNOs, and then compare the size of virtual space before and after PNO transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09003daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_LMP2 = -0.13376980554686912\n",
      "Size of Non-Truncated Virtual Space 19\n",
      "Average Size of Truncated PNO Virtual Space 14\n"
     ]
    }
   ],
   "source": [
    "D_ij = np.empty((ndocc, ndocc, nvirt, nvirt), dtype=np.float64) # Pair densities\n",
    "X_pno = np.empty((ndocc, ndocc), dtype=np.ndarray) # PNO transformation matrix\n",
    "n_pno = np.zeros((ndocc, ndocc), dtype=np.int32) # Number of Pair Natural Orbitals per MO pair ij\n",
    "e_pno = np.empty((ndocc, ndocc), dtype=np.ndarray) # PNO orbital energies per MO pair ij\n",
    "\n",
    "# Compute Fock matrix elements\n",
    "F_ao = np.asarray(scf_wfn.Fa())\n",
    "\n",
    "F_ij = np.einsum('pi,pq,qj->ij', Cocc, F_ao, Cocc, optimize=True)\n",
    "F_ab = np.einsum('pa,pq,qb->ab', Cvirt, F_ao, Cvirt, optimize=True)\n",
    "assert(np.allclose(np.diag(F_ij), e_ij))\n",
    "assert(np.allclose(np.diag(F_ab), e_ab))\n",
    "\n",
    "# Occupation Number to Truncate PNOs\n",
    "T_CUT_PNO = 1.0e-8\n",
    "# T_CUT_PNO = 0.0\n",
    "\n",
    "E_LMP2 = 0.0\n",
    "\n",
    "for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "\n",
    "    if i > j: continue\n",
    "\n",
    "    D_ij[i,j] = Tt_ijab[i,j] @ T_ijab[i,j].transpose() + Tt_ijab[i,j].transpose() @ T_ijab[i,j]\n",
    "    n_occ, X_pno[i,j] = np.linalg.eigh(D_ij[i,j])\n",
    "    \n",
    "    # Truncate PNOs based on occupation number\n",
    "    for occ_num in n_occ:\n",
    "        if (occ_num >= T_CUT_PNO):\n",
    "            n_pno[i,j] += 1\n",
    "    # n_pno[i,j] = 19\n",
    "        \n",
    "    X_pno[i,j] = X_pno[i,j][:,-n_pno[i,j]:]\n",
    "\n",
    "    # Canonicalize PNOs\n",
    "    e_pno_temp = np.linalg.multi_dot([X_pno[i,j].T, F_ab, X_pno[i,j]])\n",
    "    e_pno_ij, pno_canon = np.linalg.eigh(e_pno_temp)\n",
    "    # print(f\"{e_pno_ij = } {i = } {j = }\")\n",
    "    X_pno[i,j] = X_pno[i,j] @ pno_canon\n",
    "\n",
    "    #F_ab_canon = np.linalg.multi_dot([X_pno[i,j].T, F_ab, X_pno[i,j]])\n",
    "    #F_ab_canon_off_diag = F_ab_canon - np.diag(np.diag(F_ab_canon))\n",
    "    #print(np.sum(np.abs(F_ab_canon_off_diag), axis=None))\n",
    "\n",
    "    K_ij = X_pno[i,j].T @ K_ijab[i,j] @ X_pno[i,j]\n",
    "    T_ij = K_ij.copy()\n",
    "    for a, b in itertools.product(range(n_pno[i,j]), range(n_pno[i,j])):\n",
    "        T_ij[a,b] = T_ij[a,b] / (-e_pno_ij[a] - e_pno_ij[b] + F_ij[i,i] + F_ij[j,j])\n",
    "    \n",
    "    E_LMP2 += np.dot((2.0 * T_ij - T_ij.T).flatten(), K_ij.flatten())\n",
    "    \n",
    "    e_pno[i,j] = e_pno_ij\n",
    "\n",
    "for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "    if i < j:\n",
    "        e_pno[j,i] = e_pno[i,j].copy()\n",
    "        X_pno[j,i] = X_pno[i,j].copy()\n",
    "        n_pno[j,i] = n_pno[i,j].copy()\n",
    "\n",
    "print(f'{E_LMP2 = }')\n",
    "# Compare virtual space sizes with and without PNOs\n",
    "print('Size of Non-Truncated Virtual Space', nvirt)\n",
    "print('Average Size of Truncated PNO Virtual Space', int(np.round(np.mean(n_pno))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32ae018f",
   "metadata": {},
   "source": [
    "The size reduction is not great for a small molecule like water, but the difference between the canonical MO size and the PNO size becomes greatly exaggerated for larger systems. Next, we need to recompute the integrals in the PNO basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf92223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qij = np.einsum('pi,Qpq,qj->Qij', Cocc, Qpq, Cocc, optimize=True)\n",
    "Qia = np.einsum('pi,Qpq,qa->Qia', Cocc, Qpq, Cvirt, optimize=True)\n",
    "Qab = np.einsum('pa,Qpq,qb->Qab', Cvirt, Qpq, Cvirt, optimize=True)\n",
    "\n",
    "# => Compute all the integral classes in Jiang 2023 <= #\n",
    "\n",
    "K_occ = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 50\n",
    "\n",
    "K_bar = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 51\n",
    "L_bar = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 52\n",
    "\n",
    "J_ij = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 53\n",
    "K_ij = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 54\n",
    "L_ij = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 55\n",
    "M_ij = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 56\n",
    "\n",
    "K_tilde = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 57\n",
    "L_tilde = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 58\n",
    "\n",
    "Qab_ij = np.empty((ndocc, ndocc), dtype=np.ndarray) # Jiang Eq. 59\n",
    "\n",
    "for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "    K_occ[i,j] = np.einsum('Qm,Qn->mn', Qij[:,i,:], Qij[:,j,:], optimize=True)\n",
    "    \n",
    "    K_bar[i,j] = np.einsum('Qm,Qe->me', Qij[:,i,:], Qia[:,j,:], optimize=True)\n",
    "    K_bar[i,j] = np.einsum('mE,Ee->me', K_bar[i,j], X_pno[i,j], optimize=True)\n",
    "    \n",
    "    J_ij[i,j] = np.einsum('Q,Qab->ab', Qij[:,i,j], Qab, optimize=True)\n",
    "    J_ij[i,j] = np.einsum('Aa,AB,Bb->ab', X_pno[i,j], J_ij[i,j], X_pno[i,j], optimize=True)\n",
    "    \n",
    "    K_ij[i,j] = np.einsum('Qa,Qb->ab', Qia[:,i,:], Qia[:,j,:], optimize=True)\n",
    "    K_ij[i,j] = np.einsum('Aa,AB,Bb->ab', X_pno[i,j], K_ij[i,j], X_pno[i,j], optimize=True)\n",
    "    #K_ij[i,j] = X_pno[i,j].T @ K_ijab[i,j] @ X_pno[i,j]\n",
    "\n",
    "    K_tilde[i,j] = np.einsum('Qe,Qaf->eaf', Qia[:,i,:], Qab, optimize=True)\n",
    "    K_tilde[i,j] = np.einsum('EAF,Ee,Aa,Ff->eaf', K_tilde[i,j], X_pno[i,j], X_pno[i,j], X_pno[i,j], optimize=True)\n",
    "    \n",
    "    Qab_ij[i,j] = np.einsum('QAB,Aa,Bb->Qab', Qab, X_pno[i,j], X_pno[i,j], optimize=True)\n",
    "    \n",
    "for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "    L_bar[i,j] = 2.0 * K_bar[i,j] - K_bar[j,i]\n",
    "    L_ij[i,j] = 2.0 * K_ij[i,j] - K_ij[i,j].transpose()\n",
    "    M_ij[i,j] = 2.0 * K_ij[i,j] - J_ij[i,j]\n",
    "    L_tilde[i,j] = 2.0 * K_tilde[i,j] - K_tilde[i,j].transpose(2, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa204e5d",
   "metadata": {},
   "source": [
    "Now that we have our integrals, we still need to compute overlaps between PNOs of different pairs. This connects\n",
    "the virtual spaces of different pairs in the CCSD equations. Fock matrix elements are also computed for MOs and PNOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c1dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overlap matrix elements\n",
    "S_ao = np.asarray(mints.ao_overlap())\n",
    "S_mo = np.einsum('pa,pq,qb->ab', Cvirt, S_ao, Cvirt, optimize=True)\n",
    "\n",
    "S_pno = np.empty((ndocc, ndocc, ndocc, ndocc), dtype=np.ndarray)\n",
    "for i,j,k,l in itertools.product(range(ndocc), range(ndocc), range(ndocc), range(ndocc)):\n",
    "    S_pno[i,j,k,l] = np.einsum('Aa,AB,Bb->ab', X_pno[i,j], S_mo, X_pno[k,l], optimize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69c83597",
   "metadata": {},
   "source": [
    "After all of this, we are ready for our CCSD iterations. First, let us define our one-particle intermediates (Jiang Equations 60-62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f8622bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jiang Equation 60\n",
    "def compute_Fmi(T_ia, tau_tilde):\n",
    "    Fmi = F_ij.copy()\n",
    "    for m,n,i in itertools.product(range(ndocc), range(ndocc), range(ndocc)):\n",
    "        T_n = S_pno[m,n,n,n] @ T_ia[n]\n",
    "        Fmi[m,i] += np.dot(L_bar[m,n][i], T_n)\n",
    "        \n",
    "        L_temp = np.linalg.multi_dot([S_pno[i,n,m,n], L_ij[m,n], S_pno[m,n,i,n]])\n",
    "        Fmi[m,i] += np.dot(L_temp.flatten(), tau_tilde[i,n].flatten())\n",
    "        \n",
    "    return Fmi\n",
    "\n",
    "# Jiang Equation 61\n",
    "def compute_Fbe(T_ia, tau_tilde):\n",
    "    Fbe = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "    for i, j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        # Fbe[i,j] = np.linalg.multi_dot([X_pno[i,j].T, F_ab, X_pno[i,j]])\n",
    "        Fbe[i,j] = np.diag(e_pno[i,j]).copy()\n",
    "\n",
    "        for m in range(ndocc):\n",
    "            temp_a = np.einsum('fbe,F,Ff->be', L_tilde[m,j], T_ia[m], S_pno[m,m,m,j], optimize=True)\n",
    "            Fbe[i,j] += np.linalg.multi_dot([S_pno[i,j,m,j], temp_a, S_pno[m,j,i,j]])\n",
    "            for n in range(ndocc):\n",
    "                temp_b = np.einsum('bf,ef->be', tau_tilde[m,n], L_ij[m,n], optimize=True)\n",
    "                Fbe[i,j] -= np.linalg.multi_dot([S_pno[i,j,m,n], temp_b, S_pno[m,n,i,j]])\n",
    "\n",
    "    return Fbe\n",
    "\n",
    "# Jiang Equation 62\n",
    "def compute_Fme(T_ia):\n",
    "    Fme = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "    for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        Fme[i,j] = np.empty((ndocc, n_pno[i,j]), dtype=np.float64)\n",
    "        for m,n in itertools.product(range(ndocc), range(ndocc)):\n",
    "            Fme[i,j][m] = np.einsum('eE,EF,Ff,f->e', S_pno[i,j,m,n], L_ij[m,n], S_pno[m,n,n,n], T_ia[n], optimize=True)\n",
    "\n",
    "    return Fme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c49611f4",
   "metadata": {},
   "source": [
    "Next, let us define our two-particle intermediates (Jiang Equations 63-65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b1beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jiang Equation 63\n",
    "def compute_Wmnij(T_ia, tau):\n",
    "    Wmnij = np.zeros((ndocc, ndocc, ndocc, ndocc), dtype=np.float64)\n",
    "    for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        Wmnij[i,j] = K_occ[i,j].copy()\n",
    "        for m,n in itertools.product(range(ndocc), range(ndocc)):\n",
    "            Wmnij[i,j] += np.einsum('e,eE,E->', T_ia[j], S_pno[j,j,m,n], K_bar[m,n][i], optimize=True)\n",
    "            Wmnij[i,j] += np.einsum('e,eE,E->', T_ia[i], S_pno[i,i,m,n], K_bar[n,m][j], optimize=True)\n",
    "            K_temp = np.linalg.multi_dot([S_pno[i,j,m,n], K_ij[m,n], S_pno[m,n,i,j]])\n",
    "            Wmnij[i,j] += np.dot(K_temp.flatten(), tau[i,j].flatten())\n",
    "\n",
    "    return Wmnij\n",
    "\n",
    "# Jiang Equation 64\n",
    "def compute_Wbar(T_ia, tau_bar, T_ijab):\n",
    "    Wbar = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "    for m,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        Wbar[m,j] = K_ij[j,m].copy()\n",
    "        Wbar[m,j] += np.einsum('F,Ff,ebf->eb', T_ia[j], S_pno[j,j,m,j], K_tilde[m,j], optimize=True).transpose()\n",
    "        for n in range(ndocc):\n",
    "            Wbar[m,j] -= np.einsum('B,Bb,e->be', T_ia[n], S_pno[n,n,m,j], K_bar[j,m][n], optimize=True)\n",
    "            Wbar[m,j] -= np.linalg.multi_dot([S_pno[m,j,m,n], K_ij[m,n], S_pno[m,n,j,n], tau_bar[j,n], S_pno[j,n,m,j]]).transpose()\n",
    "            Wbar[m,j] += 0.5 * np.linalg.multi_dot([S_pno[m,j,m,n], L_ij[m,n], S_pno[m,n,j,n], T_ijab[n,j], S_pno[j,n,m,j]]).transpose()\n",
    "    return Wbar\n",
    "\n",
    "# Jiang Equation 65\n",
    "def compute_Wtilde(T_ia, tau_bar):\n",
    "    Wtilde = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "    for m,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        Wtilde[m,j] = -J_ij[m,j].copy()\n",
    "        Wtilde[m,j] -= np.einsum('F,Ff,fbe->be', T_ia[j], S_pno[j,j,m,j], K_tilde[m,j], optimize=True)\n",
    "        for n in range(ndocc):\n",
    "            Wtilde[m,j] += np.einsum('B,Bb,E,Ee->be', T_ia[n], S_pno[n,n,m,j], K_bar[m,n][j], S_pno[m,n,m,j], optimize=True)\n",
    "            Wtilde[m,j] += np.linalg.multi_dot([S_pno[m,j,j,n], tau_bar[j,n].T, S_pno[j,n,m,n], K_ij[m,n], S_pno[m,n,m,j]])\n",
    "\n",
    "    return Wtilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d2ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Equation 66\n",
    "def compute_Ria(T_ia, Fbe, Fmi, Fme, Tt_ijab):\n",
    "    R_ia = np.empty((ndocc), dtype=np.ndarray)\n",
    "    for i in range(ndocc):\n",
    "        R_ia[i] = np.einsum('ae,e->a', Fbe[i,i], T_ia[i], optimize=True)\n",
    "        for m in range(ndocc):\n",
    "            R_ia[i] += np.einsum(\"aA,AF,Ff,f->a\", S_pno[i,i,i,m], M_ij[i,m], S_pno[i,m,m,m], T_ia[m], optimize=True)\n",
    "            R_ia[i] -= Fmi[m,i] * np.einsum('A,Aa->a', T_ia[m], S_pno[m,m,i,i], optimize=True)\n",
    "            R_ia[i] += np.einsum('aA,AE,E->a', S_pno[i,i,i,m], Tt_ijab[i,m], Fme[i,m][m], optimize=True)\n",
    "            R_ia[i] += np.einsum('ef,eAf,Aa->a', Tt_ijab[m,i], K_tilde[m,i], S_pno[m,i,i,i], optimize=True)\n",
    "            for n in range(ndocc):\n",
    "                R_ia[i] -= np.einsum('aA,AE,E->a', S_pno[i,i,m,n], T_ijab[m,n], L_bar[m,n][i], optimize=True)\n",
    "    \n",
    "    return R_ia\n",
    "\n",
    "# Jiang Equation 67\n",
    "def compute_Rijab(T_ia, T_ijab, Tt_ijab, tau, tau_bar, tau_tilde, Fbe, Fmi, Fme, Wmnij, Wbar, Wtilde):\n",
    "    R_bar_ijab = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "    for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        R_bar_ijab[i,j] = 0.5 * K_ij[i,j].copy()\n",
    "        R_bar_ijab[i,j] += np.einsum('ae,be->ab', T_ijab[i,j], Fbe[i,j], optimize=True)\n",
    "        R_bar_ijab[i,j] += 0.5 * np.einsum('Qae,ef,Qbf->ab', Qab_ij[i,j], tau[i,j], Qab_ij[i,j])\n",
    "        R_bar_ijab[i,j] += np.einsum('E,Ee,bea->ab', T_ia[i], S_pno[i,i,i,j], K_tilde[j,i], optimize=True)\n",
    "\n",
    "        for m in range(ndocc):\n",
    "            t_tilde = np.einsum('E,Ee->e', T_ia[m], S_pno[m,m,i,j], optimize=True)\n",
    "            R_bar_ijab[i,j] -= 0.5 * np.einsum('ae,e,b->ab', T_ijab[i,j], Fme[i,j][m], t_tilde, optimize=True)\n",
    "            R_bar_ijab[i,j] -= np.einsum('a,EBF,Ee,ef,fF,Bb->ab', t_tilde, K_tilde[m,j], S_pno[m,j,i,j], tau[i,j], S_pno[i,j,m,j], S_pno[m,j,i,j], optimize=True)\n",
    "            R_bar_ijab[i,j] -= np.einsum('a,e,eE,EB,Bb->ab', t_tilde, T_ia[i], S_pno[i,i,m,j], K_ij[m,j], S_pno[m,j,i,j], optimize=True)\n",
    "            R_bar_ijab[i,j] -= np.einsum('aA,AE,e,eE,b->ab', S_pno[i,j,m,j], J_ij[m,j], T_ia[i], S_pno[i,i,m,j], t_tilde, optimize=True)\n",
    "            R_bar_ijab[i,j] -= np.einsum('a,b->ab', t_tilde, K_bar[i,j][m], optimize=True)\n",
    "            R_bar_ijab[i,j] -= np.einsum('aA,AB,Bb->ab', S_pno[i,j,i,m], T_ijab[i,m], S_pno[i,m,i,j], optimize=True) * (Fmi[m,j] + 0.5 * np.einsum('E,E->', T_ia[j], Fme[j,j][m]))\n",
    "\n",
    "            Wbar_ij = np.linalg.multi_dot([S_pno[i,j,m,j], Wbar[m,j], S_pno[m,j,i,m]])\n",
    "            R_bar_ijab[i,j] += np.linalg.multi_dot([S_pno[i,j,i,m], (T_ijab[i,m] - T_ijab[i,m].transpose()), Wbar_ij.transpose()])\n",
    "            Wsum_ij = np.linalg.multi_dot([S_pno[i,j,m,j], (Wbar[m,j] + Wtilde[m,j]), S_pno[m,j,i,m]])\n",
    "            R_bar_ijab[i,j] += np.linalg.multi_dot([S_pno[i,j,i,m], T_ijab[i,m], Wsum_ij.transpose()])\n",
    "            Wtilde_ij = np.linalg.multi_dot([S_pno[i,j,m,i], Wtilde[m,i], S_pno[m,i,m,j]])\n",
    "            R_bar_ijab[i,j] += np.linalg.multi_dot([S_pno[i,j,m,j], T_ijab[m,j], Wtilde_ij.transpose()])\n",
    "\n",
    "            for n in range(ndocc):\n",
    "                R_bar_ijab[i,j] += 0.5 * np.einsum('aA,AB,Bb->ab', S_pno[i,j,m,n], tau[m,n], S_pno[m,n,i,j], optimize=True) * Wmnij[m,n,i,j]\n",
    "    \n",
    "    R_ijab = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "    for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        R_ijab[i,j] = R_bar_ijab[i,j].copy() + R_bar_ijab[j,i].transpose() # Jiang Eq. 71\n",
    "        #v = np.sum(np.square(np.subtract(R_ijab[i,j], K_ij[i,j])), axis=None)\n",
    "    \n",
    "    return R_ijab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a75eafe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@LCCSD Iter 1, E_CCSD: -0.204122014044, dE_CCSD: -0.204122014044\n",
      "@LCCSD Iter 2, E_CCSD: -0.209989711422, dE_CCSD: -0.005867697379\n",
      "@LCCSD Iter 3, E_CCSD: -0.213667822580, dE_CCSD: -0.003678111157\n",
      "@LCCSD Iter 4, E_CCSD: -0.214624558226, dE_CCSD: -0.000956735647\n",
      "@LCCSD Iter 5, E_CCSD: -0.215015445350, dE_CCSD: -0.000390887123\n",
      "@LCCSD Iter 6, E_CCSD: -0.215169894401, dE_CCSD: -0.000154449051\n",
      "@LCCSD Iter 7, E_CCSD: -0.215236356619, dE_CCSD: -0.000066462219\n",
      "@LCCSD Iter 8, E_CCSD: -0.215265590912, dE_CCSD: -0.000029234293\n",
      "@LCCSD Iter 9, E_CCSD: -0.215278940865, dE_CCSD: -0.000013349953\n",
      "@LCCSD Iter 10, E_CCSD: -0.215285188693, dE_CCSD: -0.000006247828\n",
      "@LCCSD Iter 11, E_CCSD: -0.215288192713, dE_CCSD: -0.000003004021\n",
      "@LCCSD Iter 12, E_CCSD: -0.215289670880, dE_CCSD: -0.000001478166\n",
      "@LCCSD Iter 13, E_CCSD: -0.215290414727, dE_CCSD: -0.000000743847\n",
      "E_CCSD PSI: -0.21360221125424061\n",
      "E_PNO_CCSD: -0.21529041472678492\n"
     ]
    }
   ],
   "source": [
    "# Initialize Residuals\n",
    "R_ia = np.empty((ndocc), dtype=np.ndarray)\n",
    "R_ijab = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "\n",
    "# Initialize Amplitudes and intermediates\n",
    "T_ia = np.empty((ndocc), dtype=np.ndarray)\n",
    "T_ijab = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "Tt_ijab = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "tau = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "tau_bar = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "tau_tilde = np.empty((ndocc, ndocc), dtype=np.ndarray)\n",
    "\n",
    "# Initialize to zeros\n",
    "for i in range(ndocc):\n",
    "    T_ia[i] = np.zeros((n_pno[i,i]), dtype=np.float64)\n",
    "    R_ia[i] = np.zeros((n_pno[i,i]), dtype=np.float64)\n",
    "    for j in range(ndocc):\n",
    "        R_ijab[i,j] = np.zeros((n_pno[i,j], n_pno[i,j]), dtype=np.float64)\n",
    "        T_ijab[i,j] = R_ijab[i,j].copy()\n",
    "        Tt_ijab[i,j] = R_ijab[i,j].copy()\n",
    "        tau[i,j] = R_ijab[i,j].copy()\n",
    "        tau_bar[i,j] = R_ijab[i,j].copy()\n",
    "        tau_tilde[i,j] = R_ijab[i,j].copy()\n",
    "\n",
    "r_convergence = 1.0e-6\n",
    "e_convergence = 1.0e-6\n",
    "\n",
    "iter = 1\n",
    "maxiter = 50\n",
    "E_CCSD_old = 0.0\n",
    "\n",
    "while (iter <= maxiter):\n",
    "    # Compute One-Particle Intermediates\n",
    "    Fmi = compute_Fmi(T_ia, tau_tilde)\n",
    "    Fbe = compute_Fbe(T_ia, tau_tilde)\n",
    "    Fme = compute_Fme(T_ia)\n",
    "\n",
    "    # Compute Two-Particle Intermediates\n",
    "    Wmnij = compute_Wmnij(T_ia, tau)\n",
    "    Wbar = compute_Wbar(T_ia, tau_bar, T_ijab)\n",
    "    Wtilde = compute_Wtilde(T_ia, tau_bar)\n",
    "\n",
    "    # Compute Singles Residual\n",
    "    R_ia = compute_Ria(T_ia, Fbe, Fmi, Fme, Tt_ijab)\n",
    "\n",
    "    # Compute Doubles Residual\n",
    "    R_ijab = compute_Rijab(T_ia, T_ijab, Tt_ijab, tau, tau_bar, tau_tilde, Fbe, Fmi, Fme, Wmnij, Wbar, Wtilde)\n",
    "\n",
    "    # Update Singles and Doubles Residuals\n",
    "    for i in range(ndocc):\n",
    "        for a in range(n_pno[i,i]):\n",
    "            T_ia[i][a] -= R_ia[i][a] / (e_pno[i,i][a] - F_ij[i,i])\n",
    "    \n",
    "    for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        for a, b in itertools.product(range(n_pno[i,j]), range(n_pno[i,j])):\n",
    "            T_ijab[i,j][a,b] -= R_ijab[i,j][a,b] / (e_pno[i,j][a] + e_pno[i,j][b] - F_ij[i,i] - F_ij[j,j])\n",
    "\n",
    "    # Update the intermediates (Jiang Eq. 68 - 70)\n",
    "    for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        Tt_ijab[i,j] = 2.0 * T_ijab[i,j] - T_ijab[i,j].transpose()\n",
    "\n",
    "        TiaTjb = np.einsum('aA,A,B,Bb->ab', S_pno[i,j,i,i], T_ia[i], T_ia[j], S_pno[j,j,i,j], optimize=True)\n",
    "        tau[i,j] = T_ijab[i,j] + TiaTjb\n",
    "        tau_bar[i,j] = 0.5 * T_ijab[i,j] + TiaTjb\n",
    "        tau_tilde[i,j] = T_ijab[i,j] + 0.5 * TiaTjb\n",
    "\n",
    "    # Compute Energy (finally), Jiang Eq 74\n",
    "    E_CCSD = 0.0\n",
    "    for i,j in itertools.product(range(ndocc), range(ndocc)):\n",
    "        E_CCSD += np.einsum('ab,ab->', tau[i,j], L_ij[i,j])\n",
    "\n",
    "    dE_CCSD = E_CCSD - E_CCSD_old\n",
    "\n",
    "    print(f'@LCCSD Iter {iter}, E_CCSD: {E_CCSD:.12f}, dE_CCSD: {dE_CCSD:.12f}')\n",
    "\n",
    "    E_CCSD_old = E_CCSD\n",
    "    \n",
    "\n",
    "    if (np.abs(dE_CCSD) < e_convergence):\n",
    "        converged = True\n",
    "        break\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "E_CCSD_PSI = psi4.energy('ccsd')\n",
    "print('E_CCSD PSI:', E_CCSD_PSI - scf_e)\n",
    "print('E_PNO_CCSD:', E_CCSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0e788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
